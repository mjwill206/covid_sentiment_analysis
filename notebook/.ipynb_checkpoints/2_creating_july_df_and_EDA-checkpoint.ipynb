{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After hydration!!! - creating the July DF\n",
    "\n",
    "Hydrator app - Documenting the Now. (2020). Hydrator [Computer Software]. Retrieved from https://github.com/docnow/hydrator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING THE JULY DF FROM THE DAILIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_build_df(file):\n",
    "    df=pd.read_csv('../data/Hydrated_twitter_csvs/' + file, header=None)\n",
    "    # set column names as first row\n",
    "    df.columns = df.iloc[0]\n",
    "    # drop that first row that contains only column names\n",
    "    df = df.iloc[1:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydrated_tweet_set = os.listdir('../data/Hydrated_twitter_csvs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hydrated_tweet_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Got some kind of invisible checkpoint?\n",
    "\n",
    "if '.ipynb_checkpoints' in hydrated_tweet_set:\n",
    "    hydrated_tweet_set.remove('.ipynb_checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for file in hydrated_tweet_set:\n",
    "    df = pd.concat([df, read_and_build_df(file)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44248, 34)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "# looks good. this is what we wanted..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMOVING UNNECESSARY COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop irrelevant columns\n",
    "df = df.drop(columns=['media', 'urls', 'in_reply_to_screen_name', 'in_reply_to_status_id', 'in_reply_to_user_id',\n",
    "                      'possibly_sensitive', 'reweet_id', 'retweet_screen_name', 'source', 'tweet_url', \n",
    "                      'user_created_at', 'user_screen_name', 'user_default_profile_image', 'user_description',\n",
    "                      'user_favourites_count', 'user_friends_count', 'user_listed_count', 'user_name', \n",
    "                      'user_screen_name', 'user_statuses_count', 'user_time_zone', 'user_urls'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "coordinates                 2\n",
       "created_at                  0\n",
       "hashtags                21525\n",
       "favorite_count              0\n",
       "id                          0\n",
       "lang                        0\n",
       "place                      75\n",
       "retweet_count               0\n",
       "text                        0\n",
       "user_followers_count        0\n",
       "user_location            2713\n",
       "user_verified               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMOVING NULL PLACES\n",
    "I worked on trying to assign place by reverse geocoding in another notebook, but the coordinates were unreliable..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['place'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXING ODDLY FORMATTED PLACES --> mostly was from Puerto Rico\n",
    "\n",
    "df.at[246, 'place'] = 'Guam, USA'\n",
    "df.at[6416, 'place'] = 'Puerto Rico, USA'\n",
    "df.at[7305, 'place'] = 'Puerto Rico, USA'\n",
    "df.at[10380, 'place'] = 'Puerto Rico, USA'\n",
    "df.at[36513, 'place'] = 'Puerto Rico, USA'\n",
    "df.at[16565, 'place'] = 'Puerto Rico, USA'\n",
    "df.at[33500, 'place'] = 'Puerto Rico, USA'\n",
    "df.at[36589, 'place'] = 'Puerto Rico, USA'\n",
    "df.at[43254, 'place'] = 'Puerto Rico, USA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASSIGNING STATE ABBREVIATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAY NEED TO LOWERCASE THESE TO SEE IF WE SAVE ANY MORE DATA\n",
    "states = {\n",
    "    'Alabama': 'AL',\n",
    "    'AL': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'AK': 'AK',\n",
    "    'AmericanSamoa':'AS',\n",
    "    'American Samoa':'AS',\n",
    "    'AS':'AS',\n",
    "    'Arizona': 'AZ',\n",
    "    'AZ': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'AR': 'AR',\n",
    "    'California': 'CA',\n",
    "    'CA': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'CO': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'CT': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'DE': 'DE',\n",
    "    'DistrictofColumbia': 'DC',\n",
    "    'District of Columbia': 'DC',\n",
    "    'DC': 'DC',\n",
    "    'FederatedStatesofMicronesia': 'FM',\n",
    "    'Federated States of Micronesia': 'FM',\n",
    "    'FM':'FM',\n",
    "    'Florida':'FL',\n",
    "    'FL':'FL',\n",
    "    'Georgia':'GA',\n",
    "    'GA': 'GA',\n",
    "    'Guam':'GU',\n",
    "    'GU': 'GU',\n",
    "    'Hawaii': 'HI',\n",
    "    'HI': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'ID': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'IL': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'IN': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'IA': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'KS': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'KY': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'LA': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'ME': 'ME',\n",
    "    'MarshallIslands':'MH',\n",
    "    'Marshall Islands':'MH',\n",
    "    'MH':'MH',\n",
    "    'Maryland': 'MD',\n",
    "    'MD': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'MA': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'MI': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'MN': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'MS': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'MO': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'MT': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'NE': 'NE',\n",
    "    'Nevada':'NV',\n",
    "    'NV':'NV',\n",
    "    'NewHampshire': 'NH',\n",
    "    'New Hampshire': 'NH',\n",
    "    'NH': 'NH',\n",
    "    'NewJersey': 'NJ',\n",
    "    'New Jersey': 'NJ',\n",
    "    'NJ': 'NJ',\n",
    "    'NewMexico': 'NM',\n",
    "    'NM': 'NM',\n",
    "    'NewYork': 'NY',\n",
    "    'New York': 'NY',\n",
    "    'NY': 'NY',\n",
    "    'NorthCarolina':'NC',\n",
    "    'North Carolina':'NC',\n",
    "    'NC': 'NC',\n",
    "    'NorthDakota': 'ND',\n",
    "    'North Dakota': 'ND',\n",
    "    'ND': 'ND',\n",
    "    'NorthernMarianaIslands':'MP',\n",
    "    'Northern Mariana Islands':'MP',\n",
    "    'MP':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'OH': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'OK':'OK',\n",
    "    'Oregon':'OR',\n",
    "    'OR':'OR',\n",
    "    'Palau':'PW',\n",
    "    'PW':'PW',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'PA':'PA',\n",
    "    'PuertoRico':'PR',\n",
    "    'San Juan':'PR',\n",
    "    'SanJuan':'PR',\n",
    "    'Canas Urbano':'PR',\n",
    "    'CanasUrbano':'PR',\n",
    "    'Puerto Rico':'PR',\n",
    "    'PR':'PR',\n",
    "    'RhodeIsland':'RI',\n",
    "    'Rhode Island':'RI',\n",
    "    'RI':'RI',\n",
    "    'SouthCarolina':'SC',\n",
    "    'South Carolina':'SC',\n",
    "    'SC':'SC',\n",
    "    'SouthDakota':'SD',\n",
    "    'South Dakota':'SD',\n",
    "    'SD':'SD',\n",
    "    'Tennessee':'TN',\n",
    "    'TN':'TN',\n",
    "    'Texas':'TX',\n",
    "    'TX':'TX',\n",
    "    'Utah': 'UT',\n",
    "    'UT': 'UT',\n",
    "    'Vermont':'VT',\n",
    "    'VT':'VT',\n",
    "    'VirginIslands':'VI',\n",
    "    'Virgin Islands':'VI',\n",
    "    'VI':'VI',\n",
    "    'Virginia':'VA',\n",
    "    'VA':'VA',\n",
    "    'Washington':'WA',\n",
    "    'WA':'WA',\n",
    "    'WestVirginia':'WV',\n",
    "    'West Virginia':'WV',\n",
    "    'WV':'WV',\n",
    "    'Wisconsin':'WI',\n",
    "    'WI':'WI',\n",
    "    'Wyoming':'WY',\n",
    "    'WY':'WY',\n",
    "    'US': 'USA',\n",
    "    'USA': 'USA',\n",
    "    'America': 'USA',\n",
    "    'UnitedStatesOfAmerica': 'USA',\n",
    "    'United States Of America': 'USA',\n",
    "    'United States of America': 'USA'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_state(place):\n",
    "    \n",
    "    # nan will stay nan\n",
    "    if isinstance(place, str):\n",
    "        place = place.replace(\" \", \"\") \n",
    "        place = place.split(',')\n",
    "        \n",
    "        if place[-1] == 'USA':\n",
    "            \n",
    "            return states[place[-2]]\n",
    "            \n",
    "            \n",
    "        \n",
    "        elif place[-1] in states:\n",
    "            #print(f'place[-1]: {place[-1]} in states')\n",
    "            return states[place[-1]]\n",
    "    \n",
    "        else:\n",
    "            #print(f'place[-1]: {place[-1]} never found')\n",
    "            return np.nan\n",
    "    \n",
    "    else:\n",
    "        return np.nan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['state'] = df['place'].apply(convert_to_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['state'].notna()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEANING UP THE TEXT FOR VADER USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].replace('\\nhttp\\S+', ' ', regex=True).replace('http\\S+', ' ', regex=True).replace('www\\S+', ' ', regex=True).replace('\\n\\n\\n', ' ', regex=True).replace('\\n\\n', ' ', regex=True).replace('\\n', ' ', regex=True).replace('\\t\\t\\t', ' ', regex=True).replace('\\t\\t', ' ', regex=True).replace('\\t', ' ', regex=True).replace('&amp;', 'and', regex=True).replace('&amp', 'and', regex=True)#.replace('amp', 'and', regex=True).replace(\"&\",\"and\", regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPORT FOR SHARING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to run this again, it's already there...\n",
    "\n",
    "#df.to_csv('./Data/final_dfs/july_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
